{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "home_work_2020.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvTpNGkezKvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
        "from torch.autograd import Variable\n",
        "import csv\n",
        "import cv2\n",
        "# import matplotlib.pyplot as plt \n",
        "# import matplotlib.image as mpimg \n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "#定義參數\n",
        "train_file='/content/drive/My Drive/data/train_truth.csv'\n",
        "test_file='/content/drive/My Drive/data/test_truth.csv'\n",
        "train_path=r'/content/drive/My Drive/data/music_train/'\n",
        "test_path=r'/content/drive/My Drive/data/music_test/'\n",
        "\n",
        "batch_size = 8\n",
        "num_workers = 0\n",
        "num_epoches = 1\n",
        "learning_rate = 0.001\n",
        "num_classes = 88\n",
        "weight_decay = 0.1\n",
        "k=5\n",
        "PATH='/content/drive/My Drive/data/cnn.pth'\n",
        "final_model='/content/drive/My Drive/data/final_model.pth'\n",
        "\n",
        "\n",
        "#定義函數及網路模型\n",
        "\n",
        "def read_csv(file_name,img_path,train_yn=True):\n",
        "    img_data = []\n",
        "    img_lab = []\n",
        "    with open(file_name) as csvfile:\n",
        "    # 讀取 CSV 檔案內容\n",
        "        rows = csv.reader(csvfile)\n",
        "        for i in rows:\n",
        "            if i[1] == 'category': continue\n",
        "            print(i[0])\n",
        "            lena = cv2.imread(img_path + i[0]).astype(np.float32) / 255\n",
        "            img_data.append(torch.from_numpy(lena).reshape(-1,394,520))\n",
        "          # img_data.append(torch.from_numpy(lena.transpose(2, 0, 1)))\n",
        "            if train_yn:\n",
        "                img_lab.append(np.array(int(i[1])))\n",
        "            else:\n",
        "                img_lab.append(i[0])    \n",
        "    return img_data, img_lab\n",
        "\n",
        "class Mydataset(Dataset):\n",
        "    def __init__(self, data, label):\n",
        "        self.data = data\n",
        "        self.label = label\n",
        "    def __len__(self):\n",
        "        return  len(self.data)\n",
        "    def __getitem__(self, item):\n",
        "        data=self.data[item]\n",
        "        label=self.label[item]\n",
        "        return data, label\n",
        "\n",
        "class My_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(My_Net, self).__init__()\n",
        "        layer1=nn.Sequential()\n",
        "        layer1.add_module('conv1', nn.Conv2d(3, 256, 3, 1))\n",
        "        layer1.add_module('nb1', nn.BatchNorm2d(256))\n",
        "        layer1.add_module('relu1', nn.ReLU())\n",
        "        layer1.add_module('pool1', nn.MaxPool2d(2, 2))\n",
        "        self.layer1=layer1\n",
        "\n",
        "        layer2=nn.Sequential()\n",
        "        layer2.add_module('conv2', nn.Conv2d(256,128,3,1))\n",
        "        layer2.add_module('nb2', nn.BatchNorm2d(128))\n",
        "        layer2.add_module('relu2', nn.ReLU())\n",
        "        layer2.add_module('pool2', nn.MaxPool2d(2, 2))\n",
        "        self.layer2 = layer2\n",
        "\n",
        "        layer3 = nn.Sequential()\n",
        "        layer3.add_module('conv3', nn.Conv2d(128, 128, 1, 1))        \n",
        "        layer3.add_module('nb3', nn.BatchNorm2d(128))\n",
        "        layer3.add_module('relu3', nn.ReLU())\n",
        "        layer3.add_module('pool3', nn.MaxPool2d(2, 2))\n",
        "        self.layer3 = layer3\n",
        "\n",
        "        layer4 = nn.Sequential()\n",
        "        layer4.add_module('conv4', nn.Conv2d(128, 64, 3, 1))\n",
        "        layer4.add_module('nb4', nn.BatchNorm2d(64))\n",
        "        layer4.add_module('relu4', nn.ReLU())\n",
        "        layer4.add_module('pool4', nn.MaxPool2d(2, 2))\n",
        "        self.layer4 = layer4\n",
        "\n",
        "        layer5 = nn.Sequential()\n",
        "        layer5.add_module('conv5', nn.Conv2d(64, 32, 3, 1))\n",
        "        layer5.add_module('nb5', nn.BatchNorm2d(32))\n",
        "        layer5.add_module('relu5', nn.ReLU())\n",
        "        layer5.add_module('pool5', nn.MaxPool2d(2, 2))\n",
        "        self.layer5 = layer5\n",
        "\n",
        "        layer9 = nn.Sequential()\n",
        "        layer9.add_module('fc1', nn.Linear(4480,512))\n",
        "        # layer9.add_module('dp1', nn.Dropout())\n",
        "        layer9.add_module('fc1_relu', nn.ReLU())\n",
        "        layer9.add_module('fc2', nn.Linear(512, num_classes))\n",
        "        self.layer9 = layer9\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1=self.layer1(x)\n",
        "        conv2=self.layer2(conv1)\n",
        "        conv3=self.layer3(conv2)\n",
        "        conv4 = self.layer4(conv3)\n",
        "        conv5 = self.layer5(conv4)\n",
        "        fc_input=conv5.view(conv5.size(0),-1)\n",
        "        fc_out=self.layer9(fc_input)\n",
        "\n",
        "        return fc_out\n",
        "\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSlFQDRqtTYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#讀取訓練資料\n",
        "tr_datas,tr_labels = read_csv(train_file,img_path=train_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Vuc13-ytZg8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#執行程式\n",
        "if __name__=='__main__':\n",
        "    ## K折訓練 5折\n",
        "    fold_size = len(tr_datas) // k\n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "    correct_K=0\n",
        "    for i in range(k):\n",
        "        val_data = tr_datas[i * fold_size:(i + 1) * fold_size]\n",
        "        val_targets = tr_labels[i * fold_size:(i + 1) * fold_size]\n",
        "        partial_train_data = tr_datas[:i * fold_size] + tr_datas[(i + 1) * fold_size:]\n",
        "        partial_train_targets = tr_labels[:i * fold_size] + tr_labels[(i + 1) * fold_size:]\n",
        "       \n",
        "        tr_dataset = Mydataset(partial_train_data, partial_train_targets)\n",
        "        val_dataset = Mydataset(val_data, val_targets)\n",
        "        # 經測試若未加shuffle=True ，訓練loss無法降低\n",
        "        train_loader = DataLoader(dataset=tr_dataset, batch_size=batch_size,shuffle=True)\n",
        "        val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size,shuffle=True)\n",
        "\n",
        "        net = My_Net()\n",
        "        if  torch.cuda.is_available():\n",
        "            net = My_Net().cuda()  \n",
        "\n",
        "        # optimizer = torch.optim.Adam(params=net.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
        "        print('-' * 25, '第', i + 1, '折', '-' * 25)\n",
        "        # 開始訓練\n",
        "        for epoch in range(num_epoches):\n",
        "            correct = 0\n",
        "            running_loss = 0.0\n",
        "            running_acc = 0.0\n",
        "            iter_no=len(train_loader)\n",
        "            for i, data in enumerate(train_loader, 1):\n",
        "                x,y = data\n",
        "                img = Variable(x)\n",
        "                label = Variable(y)\n",
        "                if torch.cuda.is_available():\n",
        "                    img = Variable(x).cuda()\n",
        "                    label = Variable(y).cuda()\n",
        "            \n",
        "                out = net(img)\n",
        "                loss = loss_func(out, label.long())\n",
        "                \n",
        "                # running_loss += loss.item() * label.size(0)\n",
        "                _, pred = torch.max(out, 1)\n",
        "                correct = (pred == label.long()).sum()\n",
        "                # accuracy = (pred == label.long()).float().mean()\n",
        "                # running_acc += num_correct.item()\n",
        "       \n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "               \n",
        "                if (i+1) % 20 == 0:\n",
        "                    print('Epoch [%d/%d], Iter [%d/%d] Loss: %.6f' %(epoch + 1, num_epoches, i+1,iter_no,loss.item()))\n",
        "                   \n",
        "\n",
        "            # 進入驗證模式\n",
        "            net.eval()\n",
        "            with torch.no_grad():\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                start = time.time()\n",
        "                # eval_loss = 0\n",
        "                # eval_acc = 0\n",
        "                for data in val_loader:\n",
        "                    x, y = data\n",
        "                    img = Variable(x)\n",
        "                    label = Variable(y)\n",
        "                    if torch.cuda.is_available():\n",
        "                        img = Variable(x).cuda()\n",
        "                        label = Variable(y).cuda()\n",
        "\n",
        "                    out = net(img)\n",
        "                    loss = loss_func(out, label.long())\n",
        "\n",
        "                    _, pred = torch.max(out.data, 1)\n",
        "                    total += label.size(0)\n",
        "                    correct += (pred == label.long()).sum().item()\n",
        "\n",
        "                stop = time.time()\n",
        "                # 保存正確率最高模型\n",
        "                if correct > correct_K:\n",
        "                    correct_K=correct\n",
        "                    torch.save(net.state_dict(), PATH)\n",
        "                print('EVAL Accuracy: {:.3f} %, Time: {:.2f}s'.format(100 * correct / total, stop - start))    \n",
        "                print()\n",
        "            net.train()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTlUhqxYIng0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 選取最佳模型，並將全部資料再訓練一次\n",
        "net = My_Net()\n",
        "if  torch.cuda.is_available():\n",
        "    net = My_Net().cuda()  \n",
        "\n",
        "        # optimizer = torch.optim.Adam(params=net.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
        "net.load_state_dict(torch.load(PATH))\n",
        "net.train()\n",
        "train_dataset = Mydataset(tr_datas,tr_labels)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size,shuffle=True)\n",
        "for i, data in enumerate(train_loader, 1):\n",
        "    x,y = data\n",
        "    img = Variable(x)\n",
        "    label = Variable(y)\n",
        "    if torch.cuda.is_available():\n",
        "        img = Variable(x).cuda()\n",
        "        label = Variable(y).cuda()\n",
        "            \n",
        "    out = net(img)\n",
        "    loss = loss_func(out, label.long())\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (i+1) % 20 == 0:\n",
        "        print(' Iter [%d/%d] Loss: %.6f' %(i, len(train_loader), loss.item()))\n",
        "    \n",
        "torch.save(net.state_dict(), final_model)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSNuPfQ9Uv1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 測試資料載入及預測\n",
        "tx_datas, file_name = read_csv(test_file, img_path=test_path,train_yn=False)\n",
        "test_dataset = Mydataset(tx_datas,file_name)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size)\n",
        "\n",
        "# tx1=torch.cat(tx_datas).float() \n",
        "# test_tensor = tx1.reshape(-1,3,394,520)\n",
        "\n",
        "outputs=[]\n",
        "net = My_Net()\n",
        "if  torch.cuda.is_available():\n",
        "    net = My_Net().cuda()  \n",
        "# net.load_state_dict(torch.load(PATH))\n",
        "#載入最後訓練模型資料\n",
        "net.load_state_dict(torch.load(final_model))\n",
        "net.eval()\n",
        "with torch.no_grad():  # disable auto-grad\n",
        "    # 若不做no_grad() 記憶體會吃爆\n",
        "    for data in test_loader:\n",
        "        img, _ = data\n",
        "        if torch.cuda.is_available():\n",
        "            test_pred = net(img.cuda())\n",
        "        else:\n",
        "            test_pred = net(img)\n",
        "\n",
        "        labelout = torch.argmax(test_pred, dim=1)\n",
        "        outputs.append(labelout.cpu())\n",
        "\n",
        "output=torch.cat(outputs).int()  \n",
        "# #將預測結果轉資料格式並寫入 CSV檔，最後將此結果上傳Kaggle\n",
        "print('測試完成，預測結果寫入 CSV檔')\n",
        "res = pd.DataFrame({'filename': file_name, 'category': output})\n",
        "res.to_csv('./output.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}